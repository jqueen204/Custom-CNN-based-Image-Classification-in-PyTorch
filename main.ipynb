{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 피부질환 Classification "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXQT_AwW8k0x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-9EF7P_8mwm"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def read_data_set(self):\n",
        "\n",
        "        all_img_files = []\n",
        "        all_labels = []\n",
        "\n",
        "        class_names = os.walk(self.data_set_path).__next__()[1]\n",
        "\n",
        "        for index, class_name in enumerate(class_names):\n",
        "            label = index\n",
        "            img_dir = os.path.join(self.data_set_path, class_name)\n",
        "            img_files = os.walk(img_dir).__next__()[2]\n",
        "\n",
        "            for img_file in img_files:\n",
        "                img_file = os.path.join(img_dir, img_file)\n",
        "                img = Image.open(img_file)\n",
        "                if img is not None:\n",
        "                    all_img_files.append(img_file)\n",
        "                    all_labels.append(label)\n",
        "\n",
        "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
        "\n",
        "    def __init__(self, data_set_path, transforms=None):\n",
        "        self.data_set_path = data_set_path\n",
        "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.image_files_path[index])\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return {'image': image, 'label': self.labels[index]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 드롭아웃 적용 O\n",
        "\n",
        "# class Convbox(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, stride=1, dropout_rate=0.1):\n",
        "#         super(Convbox, self).__init__()\n",
        "#         # 첫 번째 컨볼루션 레이어\n",
        "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.dropout = nn.Dropout2d(p=dropout_rate)\n",
        "#         # 두 번째 컨볼루션 레이어\n",
        "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "#         #  네트워크의 깊이를 늘릴 때 발생하는 그래디언트 소실 문제를 완화(앞선의 입력을 더해줌으로써)\n",
        "#         self.storage = nn.Sequential()\n",
        "#         if stride != 1 or in_channels != out_channels:\n",
        "#             self.storage = nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels)\n",
        "#             )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         storage = self.storage(x)  # 스킵 연결 부분을 먼저 계산\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "#         out = self.dropout(out)  # dropout층 추\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "#         if storage.size(2) != out.size(2) or storage.size(3) != out.size(3):\n",
        "#             storage = F.interpolate(storage, size=(out.size(2), out.size(3)), mode='nearest')\n",
        "#         out += storage  # 스킵 연결을 더함\n",
        "#         out = self.relu(out)\n",
        "#         return out\n",
        "\n",
        "# class CustomSkinClassification(nn.Module):\n",
        "#     def __init__(self, num_classes,dropout_rate=0.1):\n",
        "#         super(CustomSkinClassification, self).__init__()\n",
        "\n",
        "#         # 초기 컨볼루션 레이어\n",
        "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "#         self.dropout = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "\n",
        "#         # Convbox Layer 1\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             Convbox(64, 64),\n",
        "#             Convbox(64, 64),\n",
        "#             Convbox(64, 64)\n",
        "#         )\n",
        "\n",
        "#         # Convbox Layer 2\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             Convbox(64, 128, stride=2),\n",
        "#             Convbox(128, 128),\n",
        "#             Convbox(128, 128),\n",
        "#             Convbox(128, 128, dropout_rate=dropout_rate)\n",
        "#         )\n",
        "\n",
        "#         # Convbox Layer 3\n",
        "#         self.layer3 = nn.Sequential(\n",
        "#             Convbox(128, 256, stride=2),\n",
        "#             Convbox(256, 256),\n",
        "#             Convbox(256, 256),\n",
        "#             Convbox(256, 256),\n",
        "#             Convbox(256, 256),\n",
        "#             Convbox(256, 256,dropout_rate=dropout_rate)\n",
        "#         )\n",
        "\n",
        "#         # Convbox Layer 4\n",
        "#         self.layer4 = nn.Sequential(\n",
        "#             Convbox(256, 512, stride=2),\n",
        "#             Convbox(512, 512),\n",
        "#             Convbox(512, 512,dropout_rate=dropout_rate)\n",
        "#         )\n",
        "\n",
        "#         # Global Average Pooling 및 Fully Connected Layer\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.maxpool(x)\n",
        "\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         x = self.avgpool(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc(x)\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWkH-pXw8mzJ"
      },
      "outputs": [],
      "source": [
        "# 드롭아웃 적용 X\n",
        "\n",
        "class Convbox(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Convbox, self).__init__()\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        #  네트워크의 깊이를 늘릴 때 발생하는 그래디언트 소실 문제를 완화(앞선의 입력을 더해줌으로써)\n",
        "        self.storage = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.storage = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        storage = self.storage(x)  # 스킵 연결 부분을 먼저 계산\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if storage.size(2) != out.size(2) or storage.size(3) != out.size(3):\n",
        "            storage = F.interpolate(storage, size=(out.size(2), out.size(3)), mode='nearest')\n",
        "        out += storage  # 스킵 연결을 더함\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class CustomSkinClassification(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomSkinClassification, self).__init__()\n",
        "\n",
        "        # 초기 컨볼루션 레이어\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Convbox Layer 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            Convbox(64, 64),\n",
        "            Convbox(64, 64),\n",
        "            Convbox(64, 64)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 2\n",
        "        self.layer2 = nn.Sequential(\n",
        "            Convbox(64, 128, stride=2),\n",
        "            Convbox(128, 128),\n",
        "            Convbox(128, 128),\n",
        "            Convbox(128, 128)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 3\n",
        "        self.layer3 = nn.Sequential(\n",
        "            Convbox(128, 256, stride=2),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 4\n",
        "        self.layer4 = nn.Sequential(\n",
        "            Convbox(256, 512, stride=2),\n",
        "            Convbox(512, 512),\n",
        "            Convbox(512, 512)\n",
        "        )\n",
        "\n",
        "        # Global Average Pooling 및 Fully Connected Layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 출력 tensor가 맞는지 확인\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(CustomSkinClassification(num_classes=4), input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnUfWfMh8m1R"
      },
      "outputs": [],
      "source": [
        "hyper_param_epoch = 10\n",
        "hyper_param_batch = 64\n",
        "hyper_param_learning_rate = 0.001\n",
        "\n",
        "resize_train_mean=[0.485, 0.456, 0.406]\n",
        "resize_train_std=[0.229, 0.224, 0.225]\n",
        "\n",
        "resize_test_mean=[0.485, 0.456, 0.406]\n",
        "resize_test_std=[0.229, 0.224, 0.225]\n",
        "\n",
        "# # 둘 중 하나 택1 (위에 것하고)\n",
        "# resize_train_mean=[0.17191947, 0.41128376, 0.56153077]\n",
        "# resize_train_std=[0.16150557, 0.16577946, 0.16063999]\n",
        "\n",
        "# resize_test_mean=[0.15918699, 0.410329, 0.55247366]\n",
        "# resize_test_std=[0.1542138, 0.16098696, 0.15552239]\n",
        "\n",
        "\n",
        "# 선택.1\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)), # 이미지 resize\n",
        "    transforms.RandomCrop(224), # 이미지를 랜덤으로 크롭\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(resize_train_mean, resize_train_std)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224), # 이미지를 랜덤으로 크롭\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(resize_test_mean, resize_test_std)\n",
        "])\n",
        "\n",
        "\n",
        "# 선택.2\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.Resize((128, 128)), # 이미지 resize\n",
        "#     transforms.RandomCrop(124), # 이미지를 랜덤으로 크롭\n",
        "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), # 이미지 지터링(밝기, 대조, 채비, 색조)\n",
        "#     transforms.RandomHorizontalFlip(p = 1), # p확률로 이미지 좌우반전\n",
        "#     transforms.RandomVerticalFlip(p = 1), # p확률로 상하반전\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(resize_train_mean, resize_train_std)\n",
        "# ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.Resize((128, 128)), \n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(resize_test_mean, resize_test_std)\n",
        "# ])\n",
        "\n",
        "\n",
        "# # 선택.3\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.Resize((256, 256)), # 이미지 resize\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.Resize((256, 256)),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "train_data_set = CustomImageDataset(data_set_path=\"/content/drive/MyDrive/data/version1/train\", transforms=transforms_train)\n",
        "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
        "\n",
        "test_data_set = CustomImageDataset(data_set_path=\"/content/drive/MyDrive/data/version1/test\", transforms=transforms_test)\n",
        "test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 드롭아웃 적용 O\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# num_classes = train_data_set.num_classes\n",
        "# custom_model = CustomSkinClassification(num_classes=num_classes,dropout_rate=0.1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIy-gNj18m3d"
      },
      "outputs": [],
      "source": [
        "# 드롭아웃 적용 X\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_classes = train_data_set.num_classes\n",
        "custom_model = CustomSkinClassification(num_classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYJMypQr8k3G"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu4CZ-U48k5x"
      },
      "outputs": [],
      "source": [
        "for e in range(hyper_param_epoch):\n",
        "    custom_model.train()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for i_batch, item in enumerate(train_loader):\n",
        "        images = item['image'].to(device)\n",
        "        labels = item['label'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = custom_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted_train == labels).sum().item()\n",
        "\n",
        "        if (i_batch + 1) % hyper_param_batch == 0:\n",
        "            print('에포크 [{}/{}], 배치 [{}/{}], 훈련 손실: {:.4f}'\n",
        "                  .format(e + 1, hyper_param_epoch, i_batch + 1, len(train_loader), loss.item()))\n",
        "\n",
        "    # 훈련 정확도 기록\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print('훈련데이터 {}개에 대한 정확도: {} %'.format(total_train, train_accuracy))\n",
        "\n",
        "    # Test the model\n",
        "    custom_model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        for item in test_loader:\n",
        "            images = item['image'].to(device)\n",
        "            labels = item['label'].to(device)\n",
        "            outputs = custom_model(images)\n",
        "            _, predicted_test = torch.max(outputs.data, 1)\n",
        "            total_test += len(labels)\n",
        "            correct_test += (predicted_test == labels).sum().item()\n",
        "\n",
        "        # 테스트 정확도 기록\n",
        "        test_accuracy = 100 * correct_test / total_test\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        print('테스트 데이터 {}개에 대한 정확도: {} %'.format(total_test, test_accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww5yjtuW8k-B"
      },
      "outputs": [],
      "source": [
        "# 정확도 시각화\n",
        "\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 시각화\n",
        "label_tags = {0: 'acne', 1: 'Eczema', 2: 'normal_face_skin', 3: 'skin_cancer'}\n",
        "\n",
        "custom_model.eval()\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "fig.suptitle('Skin Condition Classification Predictions', fontsize=16)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
        "    data_iter = iter(test_loader)\n",
        "\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            data = next(data_iter)\n",
        "\n",
        "            images = data['image'].to(device)\n",
        "            labels = data['label'].to(device)\n",
        "\n",
        "            outputs = custom_model(images)\n",
        "            _, predicted_classes = torch.max(outputs.data, 1)\n",
        "            predicted_labels = [label_tags[pred.item()] for pred in predicted_classes]\n",
        "\n",
        "            resized_image = transforms.functional.resize(images[0], (128, 128))\n",
        "\n",
        "            title = f'Actual - {label_tags[labels[0].item()]},\\n Predicted - {predicted_labels[0]}'\n",
        "\n",
        "            correct_prediction = (predicted_classes[0] == labels[0]).item()\n",
        "\n",
        "            axes[i, j].imshow(resized_image.permute(1, 2, 0).cpu().numpy())\n",
        "            axes[i, j].set_title(title, fontsize=8)\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "            annotation_text = 'Success' if correct_prediction else 'Failure'\n",
        "            annotation_color = 'green' if correct_prediction else 'red'\n",
        "            axes[i, j].annotate(annotation_text,\n",
        "                                xy=(0.5, 0.02), xycoords='axes fraction',\n",
        "                                ha='center', va='center', color=annotation_color,\n",
        "                                bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#시현코드\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.save(custom_model.state_dict(), 'path_to_save_model.pth')\n",
        "custom_model.load_state_dict(torch.load('path_to_save_model.pth'))\n",
        "\n",
        "custom_model.eval()\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_model.to(device)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "image_path = '/content/drive/MyDrive/data/시현2.png'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "\n",
        "image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = custom_model(image)\n",
        "    probabilities = F.softmax(output, dim=1)\n",
        "    _, predicted_class = torch.max(output.data, 1)\n",
        "    predicted_label = label_tags[predicted_class.item()]\n",
        "    predicted_probability = probabilities[0, predicted_class[0]].item()\n",
        "\n",
        "\n",
        "resized_image = transforms.functional.resize(image[0], (128, 128))\n",
        "\n",
        "plt.imshow(resized_image.permute(1, 2, 0).cpu().numpy())\n",
        "plt.title(f'Predicted Class: {predicted_label}, Probability: {predicted_probability:.2f}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
