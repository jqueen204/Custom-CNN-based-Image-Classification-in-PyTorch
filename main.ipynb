{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXQT_AwW8k0x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-9EF7P_8mwm"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def read_data_set(self):\n",
        "\n",
        "        all_img_files = []\n",
        "        all_labels = []\n",
        "\n",
        "        class_names = os.walk(self.data_set_path).__next__()[1]\n",
        "\n",
        "        for index, class_name in enumerate(class_names):\n",
        "            label = index\n",
        "            img_dir = os.path.join(self.data_set_path, class_name)\n",
        "            img_files = os.walk(img_dir).__next__()[2]\n",
        "\n",
        "            for img_file in img_files:\n",
        "                img_file = os.path.join(img_dir, img_file)\n",
        "                img = Image.open(img_file)\n",
        "                if img is not None:\n",
        "                    all_img_files.append(img_file)\n",
        "                    all_labels.append(label)\n",
        "\n",
        "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
        "\n",
        "    def __init__(self, data_set_path, transforms=None):\n",
        "        self.data_set_path = data_set_path\n",
        "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.image_files_path[index])\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return {'image': image, 'label': self.labels[index]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWkH-pXw8mzJ"
      },
      "outputs": [],
      "source": [
        "# 드롭아웃 적용 X\n",
        "\n",
        "class Convbox(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Convbox, self).__init__()\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        #  네트워크의 깊이를 늘릴 때 발생하는 그래디언트 소실 문제를 완화(앞선의 입력을 더해줌으로써)\n",
        "        self.storage = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.storage = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        storage = self.storage(x)  # 스킵 연결 부분을 먼저 계산\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if storage.size(2) != out.size(2) or storage.size(3) != out.size(3):\n",
        "            storage = F.interpolate(storage, size=(out.size(2), out.size(3)), mode='nearest')\n",
        "        out += storage  # 스킵 연결을 더함\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class CustomSkinClassification(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomSkinClassification, self).__init__()\n",
        "\n",
        "        # 초기 컨볼루션 레이어\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Convbox Layer 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            Convbox(64, 64),\n",
        "            Convbox(64, 64),\n",
        "            Convbox(64, 64)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 2\n",
        "        self.layer2 = nn.Sequential(\n",
        "            Convbox(64, 128, stride=2),\n",
        "            Convbox(128, 128),\n",
        "            Convbox(128, 128),\n",
        "            Convbox(128, 128)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 3\n",
        "        self.layer3 = nn.Sequential(\n",
        "            Convbox(128, 256, stride=2),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256),\n",
        "            Convbox(256, 256)\n",
        "        )\n",
        "\n",
        "        # Convbox Layer 4\n",
        "        self.layer4 = nn.Sequential(\n",
        "            Convbox(256, 512, stride=2),\n",
        "            Convbox(512, 512),\n",
        "            Convbox(512, 512)\n",
        "        )\n",
        "\n",
        "        # Global Average Pooling 및 Fully Connected Layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnUfWfMh8m1R"
      },
      "outputs": [],
      "source": [
        "hyper_param_epoch = 20\n",
        "hyper_param_batch = 64\n",
        "hyper_param_learning_rate = 0.001\n",
        "\n",
        "transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                       transforms.RandomRotation(10.),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "transforms_test = transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_data_set = CustomImageDataset(data_set_path=\"./data/train\", transforms=transforms_train)\n",
        "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
        "\n",
        "test_data_set = CustomImageDataset(data_set_path=\"./data/test\", transforms=transforms_test)\n",
        "test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIy-gNj18m3d"
      },
      "outputs": [],
      "source": [
        "if not (train_data_set.num_classes == test_data_set.num_classes):\n",
        "    print(\"error: Numbers of class in training set and test set are not equal\")\n",
        "    exit()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_classes = train_data_set.num_classes\n",
        "custom_model = CustomSkinClassification(num_classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYJMypQr8k3G"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu4CZ-U48k5x"
      },
      "outputs": [],
      "source": [
        "for e in range(hyper_param_epoch):\n",
        "    for i_batch, item in enumerate(train_loader):\n",
        "        images = item['image'].to(device)\n",
        "        labels = item['label'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = custom_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i_batch + 1) % hyper_param_batch == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
        "                  .format(e + 1, hyper_param_epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqHHCUXO8k8B"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for item in test_loader:\n",
        "        images = item['image'].to(device)\n",
        "        labels = item['label'].to(device)\n",
        "        outputs = custom_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww5yjtuW8k-B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
